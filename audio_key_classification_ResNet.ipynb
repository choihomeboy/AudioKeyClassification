{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from dataloader import KeyDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from signal_process import signal_process\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data paths\n",
    "metadata_path = 'metadata.csv'\n",
    "audio_dir = 'audio'\n",
    "\n",
    "# example : ckpt/model.pth\n",
    "ckpt_dir = 'ckpt'\n",
    "best_saved_model = 'best_model.pth'\n",
    "if not os.path.exists(ckpt_dir):\n",
    "    os.mkdir(ckpt_dir)\n",
    "restore_path = os.path.join(ckpt_dir, best_saved_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyper_parameters\n",
    "n_epochs = 300\n",
    "batch_size = 16\n",
    "num_label = 24\n",
    "method = 'logmelspectrogram'\n",
    "sr = 22050\n",
    "learning_rate = 1e-3\n",
    "momentum = 0.9\n",
    "weight_decay=1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO : Build your model here\n",
    "class View(nn.Module):\n",
    "    \n",
    "    def __init__(self, *shape): \n",
    "        super(View, self).__init__() \n",
    "        self.shape = shape\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return x.view(x.shape[0], *self.shape) # x.shape = [batch_size, channel, width, height]\n",
    "    \n",
    "class Residual_Block(nn.Module):  # Residual Block 만들기 \n",
    "    \n",
    "    def __init__(self, n_ch): # pre activation 적용한 것 (2번째 논문 5번 그림)\n",
    "        super(Residual_Block, self).__init__() \n",
    "        layers = []\n",
    "        layers += [nn.BatchNorm2d(num_features=n_ch),\n",
    "                  nn.ReLU(inplace=True), \n",
    "                  nn.Conv2d(in_channels=n_ch, out_channels=n_ch, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "                  nn.BatchNorm2d(num_features=n_ch),\n",
    "                  nn.ReLU(inplace=True),\n",
    "                  nn.Conv2d(in_channels=n_ch, out_channels=n_ch, kernel_size=3, stride=1, padding=1, bias=False)]\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        out = self.layers(x)\n",
    "        return x + out\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(ResNet, self).__init__()\n",
    "        \n",
    "        # mnist니까 in_channels=1, 논문에서 out_channels=64, kernel_size=7, stride=2 (논문에선 사이즈 줄이기 위해 - 28*28이 14*14로)\n",
    "        # 사이즈 안 줄게 하는 padding 공식 = (kernel_size-1)/2\n",
    "        \n",
    "        # 우리는 Residual_Block 2개씩만 하고 (논문은 3개씩), in_channel은 64랑 256만.\n",
    "        \n",
    "        layers = []\n",
    "        layers += [nn.Conv2d(in_channels=1, out_channels=64, kernel_size=7, stride=2, padding=3), # batch * 64 * 14 * 14\n",
    "                   nn.MaxPool2d(kernel_size=3, stride=2, padding=1), # batch * 64 * 7 * 7\n",
    "                   Residual_Block(n_ch=64),\n",
    "                   Residual_Block(n_ch=64),\n",
    "                   nn.BatchNorm2d(64), # Residual_Block 거치면 x가 새롭게 추가 되니까 그것에 대해서도 BN (논문에선 안함)\n",
    "                   nn.Conv2d(in_channels=64, out_channels=256, kernel_size=3, padding=1),\n",
    "                   Residual_Block(n_ch=256),\n",
    "                   Residual_Block(n_ch=256), # batch * 256 * 7 * 7\n",
    "                   nn.AdaptiveAvgPool2d((1,1)), # batch * 256 * 1 * 1: (1,1)은 입력되는 커널 사이즈가 아니라 그렇게 나가도록 하라는 것\n",
    "                   View(-1), # batch * 256 * 1 * 1 는 우리가 보기에 1차원이지만 컴퓨터가 보기엔 4차원이므로 그걸 해결하기 위함\n",
    "                   nn.Linear(in_features=256, out_features=24)]\n",
    "                      \n",
    "        self.layers = nn.Sequential(*layers)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        return self.layers(x)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "==== Epoch: 0, Train Loss: 3.10, Train Accuracy: 0.087\n",
      "==== Epoch: 0, Valid Loss: 3.09, Valid Accuracy: 0.105\n",
      "updated\n",
      "0\n",
      "100\n",
      "200\n",
      "==== Epoch: 1, Train Loss: 3.04, Train Accuracy: 0.096\n",
      "==== Epoch: 1, Valid Loss: 3.06, Valid Accuracy: 0.096\n",
      "0\n",
      "100\n",
      "200\n",
      "==== Epoch: 2, Train Loss: 2.95, Train Accuracy: 0.125\n",
      "==== Epoch: 2, Valid Loss: 2.92, Valid Accuracy: 0.133\n",
      "updated\n",
      "0\n",
      "100\n",
      "200\n",
      "==== Epoch: 3, Train Loss: 2.78, Train Accuracy: 0.167\n",
      "==== Epoch: 3, Valid Loss: 4.18, Valid Accuracy: 0.051\n",
      "0\n",
      "100\n",
      "200\n",
      "==== Epoch: 4, Train Loss: 2.59, Train Accuracy: 0.220\n",
      "==== Epoch: 4, Valid Loss: 2.85, Valid Accuracy: 0.194\n",
      "updated\n",
      "0\n",
      "100\n",
      "200\n",
      "==== Epoch: 5, Train Loss: 2.44, Train Accuracy: 0.263\n",
      "==== Epoch: 5, Valid Loss: 2.50, Valid Accuracy: 0.223\n",
      "updated\n",
      "0\n",
      "100\n",
      "200\n",
      "==== Epoch: 6, Train Loss: 2.29, Train Accuracy: 0.308\n",
      "==== Epoch: 6, Valid Loss: 2.42, Valid Accuracy: 0.240\n",
      "updated\n",
      "0\n",
      "100\n",
      "200\n",
      "==== Epoch: 7, Train Loss: 2.15, Train Accuracy: 0.346\n",
      "==== Epoch: 7, Valid Loss: 2.60, Valid Accuracy: 0.283\n",
      "updated\n",
      "0\n",
      "100\n",
      "200\n",
      "==== Epoch: 8, Train Loss: 2.02, Train Accuracy: 0.378\n",
      "==== Epoch: 8, Valid Loss: 2.23, Valid Accuracy: 0.311\n",
      "updated\n",
      "0\n",
      "100\n",
      "200\n",
      "==== Epoch: 9, Train Loss: 1.91, Train Accuracy: 0.416\n",
      "==== Epoch: 9, Valid Loss: 2.57, Valid Accuracy: 0.289\n",
      "0\n",
      "100\n",
      "200\n",
      "==== Epoch: 10, Train Loss: 1.82, Train Accuracy: 0.440\n",
      "==== Epoch: 10, Valid Loss: 2.25, Valid Accuracy: 0.337\n",
      "updated\n",
      "0\n",
      "100\n",
      "200\n",
      "==== Epoch: 11, Train Loss: 1.70, Train Accuracy: 0.475\n",
      "==== Epoch: 11, Valid Loss: 2.10, Valid Accuracy: 0.352\n",
      "updated\n",
      "0\n",
      "100\n",
      "200\n",
      "==== Epoch: 12, Train Loss: 1.66, Train Accuracy: 0.488\n",
      "==== Epoch: 12, Valid Loss: 2.57, Valid Accuracy: 0.288\n",
      "0\n",
      "100\n",
      "200\n",
      "==== Epoch: 13, Train Loss: 1.54, Train Accuracy: 0.517\n",
      "==== Epoch: 13, Valid Loss: 2.30, Valid Accuracy: 0.355\n",
      "updated\n",
      "0\n",
      "100\n",
      "200\n",
      "==== Epoch: 14, Train Loss: 1.51, Train Accuracy: 0.529\n",
      "==== Epoch: 14, Valid Loss: 2.43, Valid Accuracy: 0.313\n",
      "0\n",
      "100\n",
      "200\n",
      "==== Epoch: 15, Train Loss: 1.43, Train Accuracy: 0.548\n",
      "==== Epoch: 15, Valid Loss: 1.76, Valid Accuracy: 0.445\n",
      "updated\n",
      "0\n",
      "100\n",
      "200\n",
      "==== Epoch: 16, Train Loss: 1.39, Train Accuracy: 0.554\n",
      "==== Epoch: 16, Valid Loss: 2.06, Valid Accuracy: 0.381\n",
      "0\n",
      "100\n",
      "200\n",
      "==== Epoch: 17, Train Loss: 1.33, Train Accuracy: 0.575\n",
      "==== Epoch: 17, Valid Loss: 1.92, Valid Accuracy: 0.423\n",
      "0\n",
      "100\n",
      "200\n",
      "==== Epoch: 18, Train Loss: 1.26, Train Accuracy: 0.597\n",
      "==== Epoch: 18, Valid Loss: 2.47, Valid Accuracy: 0.332\n",
      "0\n",
      "100\n",
      "200\n",
      "==== Epoch: 19, Train Loss: 1.25, Train Accuracy: 0.606\n",
      "==== Epoch: 19, Valid Loss: 2.40, Valid Accuracy: 0.352\n",
      "0\n",
      "100\n",
      "200\n",
      "==== Epoch: 20, Train Loss: 1.17, Train Accuracy: 0.626\n",
      "==== Epoch: 20, Valid Loss: 1.62, Valid Accuracy: 0.496\n",
      "updated\n",
      "0\n",
      "100\n",
      "200\n",
      "==== Epoch: 21, Train Loss: 1.12, Train Accuracy: 0.641\n",
      "==== Epoch: 21, Valid Loss: 1.56, Valid Accuracy: 0.499\n",
      "updated\n",
      "0\n",
      "100\n",
      "200\n",
      "==== Epoch: 22, Train Loss: 1.09, Train Accuracy: 0.649\n",
      "==== Epoch: 22, Valid Loss: 2.20, Valid Accuracy: 0.402\n",
      "0\n",
      "100\n",
      "200\n",
      "==== Epoch: 23, Train Loss: 1.03, Train Accuracy: 0.671\n",
      "==== Epoch: 23, Valid Loss: 1.45, Valid Accuracy: 0.548\n",
      "updated\n",
      "0\n",
      "100\n",
      "200\n",
      "==== Epoch: 24, Train Loss: 1.00, Train Accuracy: 0.680\n",
      "==== Epoch: 24, Valid Loss: 1.38, Valid Accuracy: 0.574\n",
      "updated\n",
      "0\n",
      "100\n",
      "200\n",
      "==== Epoch: 25, Train Loss: 0.98, Train Accuracy: 0.696\n",
      "==== Epoch: 25, Valid Loss: 1.82, Valid Accuracy: 0.465\n",
      "updated\n",
      "0\n",
      "100\n",
      "200\n",
      "==== Epoch: 26, Train Loss: 0.93, Train Accuracy: 0.691\n",
      "==== Epoch: 26, Valid Loss: 1.50, Valid Accuracy: 0.556\n",
      "0\n",
      "100\n",
      "200\n",
      "==== Epoch: 27, Train Loss: 0.88, Train Accuracy: 0.712\n",
      "==== Epoch: 27, Valid Loss: 1.77, Valid Accuracy: 0.518\n",
      "0\n",
      "100\n",
      "200\n",
      "==== Epoch: 28, Train Loss: 0.85, Train Accuracy: 0.716\n",
      "==== Epoch: 28, Valid Loss: 2.07, Valid Accuracy: 0.437\n",
      "0\n",
      "100\n",
      "200\n",
      "==== Epoch: 29, Train Loss: 0.82, Train Accuracy: 0.732\n",
      "==== Epoch: 29, Valid Loss: 1.75, Valid Accuracy: 0.511\n",
      "0\n",
      "100\n",
      "200\n",
      "==== Epoch: 30, Train Loss: 0.77, Train Accuracy: 0.740\n",
      "==== Epoch: 30, Valid Loss: 1.78, Valid Accuracy: 0.502\n",
      "updated\n",
      "0\n",
      "100\n",
      "200\n",
      "==== Epoch: 31, Train Loss: 0.70, Train Accuracy: 0.768\n",
      "==== Epoch: 31, Valid Loss: 1.60, Valid Accuracy: 0.583\n",
      "updated\n",
      "0\n",
      "100\n",
      "200\n",
      "==== Epoch: 32, Train Loss: 0.73, Train Accuracy: 0.766\n",
      "==== Epoch: 32, Valid Loss: 1.33, Valid Accuracy: 0.583\n",
      "0\n",
      "100\n",
      "200\n",
      "==== Epoch: 33, Train Loss: 0.63, Train Accuracy: 0.793\n",
      "==== Epoch: 33, Valid Loss: 1.61, Valid Accuracy: 0.546\n",
      "0\n",
      "100\n",
      "200\n",
      "==== Epoch: 34, Train Loss: 0.63, Train Accuracy: 0.798\n",
      "==== Epoch: 34, Valid Loss: 1.75, Valid Accuracy: 0.534\n",
      "0\n",
      "100\n",
      "200\n",
      "==== Epoch: 35, Train Loss: 0.61, Train Accuracy: 0.796\n",
      "==== Epoch: 35, Valid Loss: 1.92, Valid Accuracy: 0.522\n",
      "updated\n",
      "0\n",
      "100\n",
      "200\n",
      "==== Epoch: 36, Train Loss: 0.57, Train Accuracy: 0.810\n",
      "==== Epoch: 36, Valid Loss: 1.29, Valid Accuracy: 0.620\n",
      "updated\n",
      "0\n",
      "100\n",
      "200\n",
      "==== Epoch: 37, Train Loss: 0.56, Train Accuracy: 0.815\n",
      "==== Epoch: 37, Valid Loss: 1.97, Valid Accuracy: 0.478\n",
      "0\n",
      "100\n",
      "200\n",
      "==== Epoch: 38, Train Loss: 0.53, Train Accuracy: 0.833\n",
      "==== Epoch: 38, Valid Loss: 1.15, Valid Accuracy: 0.678\n",
      "updated\n",
      "0\n",
      "100\n",
      "200\n",
      "==== Epoch: 39, Train Loss: 0.44, Train Accuracy: 0.855\n",
      "==== Epoch: 39, Valid Loss: 1.55, Valid Accuracy: 0.605\n",
      "0\n",
      "100\n",
      "200\n",
      "==== Epoch: 40, Train Loss: 0.48, Train Accuracy: 0.844\n",
      "==== Epoch: 40, Valid Loss: 1.40, Valid Accuracy: 0.635\n",
      "updated\n",
      "0\n",
      "100\n",
      "200\n",
      "==== Epoch: 41, Train Loss: 0.52, Train Accuracy: 0.830\n",
      "==== Epoch: 41, Valid Loss: 1.49, Valid Accuracy: 0.598\n",
      "0\n",
      "100\n",
      "200\n",
      "==== Epoch: 42, Train Loss: 0.45, Train Accuracy: 0.848\n",
      "==== Epoch: 42, Valid Loss: 1.57, Valid Accuracy: 0.587\n",
      "0\n",
      "100\n",
      "200\n",
      "==== Epoch: 43, Train Loss: 0.34, Train Accuracy: 0.895\n",
      "==== Epoch: 43, Valid Loss: 1.41, Valid Accuracy: 0.630\n",
      "0\n",
      "100\n",
      "200\n",
      "==== Epoch: 44, Train Loss: 0.36, Train Accuracy: 0.880\n",
      "==== Epoch: 44, Valid Loss: 1.03, Valid Accuracy: 0.702\n",
      "updated\n",
      "0\n",
      "100\n",
      "200\n",
      "==== Epoch: 45, Train Loss: 0.34, Train Accuracy: 0.896\n",
      "==== Epoch: 45, Valid Loss: 1.22, Valid Accuracy: 0.657\n",
      "updated\n",
      "0\n",
      "100\n",
      "200\n",
      "==== Epoch: 46, Train Loss: 0.36, Train Accuracy: 0.882\n",
      "==== Epoch: 46, Valid Loss: 2.39, Valid Accuracy: 0.493\n",
      "0\n",
      "100\n",
      "200\n",
      "==== Epoch: 47, Train Loss: 0.44, Train Accuracy: 0.855\n",
      "==== Epoch: 47, Valid Loss: 1.73, Valid Accuracy: 0.544\n",
      "0\n",
      "100\n",
      "200\n",
      "==== Epoch: 48, Train Loss: 0.27, Train Accuracy: 0.913\n",
      "==== Epoch: 48, Valid Loss: 1.12, Valid Accuracy: 0.692\n",
      "0\n",
      "100\n",
      "200\n",
      "==== Epoch: 49, Train Loss: 0.29, Train Accuracy: 0.911\n",
      "==== Epoch: 49, Valid Loss: 2.26, Valid Accuracy: 0.580\n",
      "0\n",
      "100\n",
      "200\n",
      "==== Epoch: 50, Train Loss: 0.31, Train Accuracy: 0.902\n",
      "==== Epoch: 50, Valid Loss: 1.08, Valid Accuracy: 0.728\n",
      "updated\n",
      "0\n",
      "100\n",
      "200\n",
      "==== Epoch: 51, Train Loss: 0.30, Train Accuracy: 0.900\n",
      "==== Epoch: 51, Valid Loss: 1.14, Valid Accuracy: 0.688\n",
      "0\n",
      "100\n",
      "200\n",
      "==== Epoch: 52, Train Loss: 0.27, Train Accuracy: 0.915\n",
      "==== Epoch: 52, Valid Loss: 1.14, Valid Accuracy: 0.715\n",
      "0\n",
      "100\n",
      "200\n",
      "==== Epoch: 53, Train Loss: 0.23, Train Accuracy: 0.928\n",
      "==== Epoch: 53, Valid Loss: 1.60, Valid Accuracy: 0.622\n",
      "0\n",
      "100\n",
      "200\n",
      "==== Epoch: 54, Train Loss: 0.18, Train Accuracy: 0.942\n",
      "==== Epoch: 54, Valid Loss: 1.07, Valid Accuracy: 0.710\n",
      "0\n",
      "100\n",
      "200\n",
      "==== Epoch: 55, Train Loss: 0.21, Train Accuracy: 0.932\n",
      "==== Epoch: 55, Valid Loss: 1.23, Valid Accuracy: 0.692\n",
      "updated\n",
      "0\n",
      "100\n",
      "200\n",
      "==== Epoch: 56, Train Loss: 0.21, Train Accuracy: 0.934\n",
      "==== Epoch: 56, Valid Loss: 1.03, Valid Accuracy: 0.720\n",
      "0\n",
      "100\n",
      "200\n",
      "==== Epoch: 57, Train Loss: 0.20, Train Accuracy: 0.930\n",
      "==== Epoch: 57, Valid Loss: 1.02, Valid Accuracy: 0.748\n",
      "updated\n",
      "0\n",
      "100\n",
      "200\n",
      "==== Epoch: 58, Train Loss: 0.09, Train Accuracy: 0.979\n",
      "==== Epoch: 58, Valid Loss: 0.67, Valid Accuracy: 0.819\n",
      "updated\n",
      "0\n",
      "100\n",
      "200\n",
      "==== Epoch: 59, Train Loss: 0.06, Train Accuracy: 0.991\n",
      "==== Epoch: 59, Valid Loss: 0.66, Valid Accuracy: 0.828\n",
      "updated\n",
      "0\n",
      "100\n",
      "200\n",
      "==== Epoch: 60, Train Loss: 0.06, Train Accuracy: 0.988\n",
      "==== Epoch: 60, Valid Loss: 0.63, Valid Accuracy: 0.819\n",
      "updated\n",
      "0\n",
      "100\n",
      "200\n",
      "==== Epoch: 61, Train Loss: 0.04, Train Accuracy: 0.996\n",
      "==== Epoch: 61, Valid Loss: 0.64, Valid Accuracy: 0.837\n",
      "updated\n",
      "0\n",
      "100\n",
      "200\n",
      "==== Epoch: 62, Train Loss: 0.05, Train Accuracy: 0.993\n",
      "==== Epoch: 62, Valid Loss: 0.65, Valid Accuracy: 0.830\n",
      "0\n",
      "100\n",
      "200\n",
      "==== Epoch: 63, Train Loss: 0.05, Train Accuracy: 0.994\n",
      "==== Epoch: 63, Valid Loss: 0.62, Valid Accuracy: 0.828\n",
      "0\n",
      "100\n",
      "200\n",
      "==== Epoch: 64, Train Loss: 0.04, Train Accuracy: 0.995\n",
      "==== Epoch: 64, Valid Loss: 0.63, Valid Accuracy: 0.845\n",
      "updated\n",
      "0\n",
      "100\n",
      "200\n",
      "==== Epoch: 65, Train Loss: 0.04, Train Accuracy: 0.994\n",
      "==== Epoch: 65, Valid Loss: 0.61, Valid Accuracy: 0.838\n",
      "updated\n",
      "0\n",
      "100\n",
      "200\n",
      "==== Epoch: 66, Train Loss: 0.04, Train Accuracy: 0.994\n",
      "==== Epoch: 66, Valid Loss: 0.62, Valid Accuracy: 0.840\n",
      "0\n",
      "100\n",
      "200\n",
      "==== Epoch: 67, Train Loss: 0.04, Train Accuracy: 0.996\n",
      "==== Epoch: 67, Valid Loss: 0.60, Valid Accuracy: 0.837\n",
      "0\n",
      "100\n",
      "200\n",
      "==== Epoch: 68, Train Loss: 0.03, Train Accuracy: 0.996\n",
      "==== Epoch: 68, Valid Loss: 0.59, Valid Accuracy: 0.837\n",
      "0\n",
      "100\n",
      "200\n",
      "==== Epoch: 69, Train Loss: 0.04, Train Accuracy: 0.996\n",
      "==== Epoch: 69, Valid Loss: 0.61, Valid Accuracy: 0.842\n",
      "0\n",
      "100\n",
      "200\n",
      "==== Epoch: 70, Train Loss: 0.03, Train Accuracy: 0.997\n",
      "==== Epoch: 70, Valid Loss: 0.62, Valid Accuracy: 0.840\n",
      "updated\n",
      "0\n",
      "100\n",
      "200\n",
      "==== Epoch: 71, Train Loss: 0.04, Train Accuracy: 0.994\n",
      "==== Epoch: 71, Valid Loss: 0.65, Valid Accuracy: 0.834\n",
      "0\n",
      "100\n",
      "200\n",
      "==== Epoch: 72, Train Loss: 0.04, Train Accuracy: 0.996\n",
      "==== Epoch: 72, Valid Loss: 0.58, Valid Accuracy: 0.844\n",
      "0\n",
      "100\n",
      "200\n",
      "==== Epoch: 73, Train Loss: 0.03, Train Accuracy: 0.997\n",
      "==== Epoch: 73, Valid Loss: 0.60, Valid Accuracy: 0.835\n",
      "0\n",
      "100\n",
      "200\n",
      "==== Epoch: 74, Train Loss: 0.03, Train Accuracy: 0.997\n",
      "==== Epoch: 74, Valid Loss: 0.63, Valid Accuracy: 0.839\n",
      "0\n",
      "100\n",
      "200\n",
      "==== Epoch: 75, Train Loss: 0.04, Train Accuracy: 0.997\n",
      "==== Epoch: 75, Valid Loss: 0.60, Valid Accuracy: 0.829\n",
      "updated\n",
      "0\n",
      "100\n",
      "200\n",
      "==== Epoch: 76, Train Loss: 0.03, Train Accuracy: 0.997\n",
      "==== Epoch: 76, Valid Loss: 0.61, Valid Accuracy: 0.839\n",
      "0\n",
      "100\n",
      "200\n",
      "==== Epoch: 77, Train Loss: 0.04, Train Accuracy: 0.994\n",
      "==== Epoch: 77, Valid Loss: 0.64, Valid Accuracy: 0.842\n",
      "0\n",
      "100\n",
      "200\n",
      "==== Epoch: 78, Train Loss: 0.04, Train Accuracy: 0.998\n",
      "==== Epoch: 78, Valid Loss: 0.60, Valid Accuracy: 0.845\n",
      "0\n",
      "100\n",
      "200\n",
      "==== Epoch: 79, Train Loss: 0.03, Train Accuracy: 0.996\n",
      "==== Epoch: 79, Valid Loss: 0.63, Valid Accuracy: 0.845\n",
      "0\n",
      "100\n",
      "200\n",
      "==== Epoch: 80, Train Loss: 0.03, Train Accuracy: 0.998\n",
      "==== Epoch: 80, Valid Loss: 0.61, Valid Accuracy: 0.847\n",
      "updated\n",
      "0\n",
      "100\n",
      "200\n",
      "==== Epoch: 81, Train Loss: 0.03, Train Accuracy: 0.998\n",
      "==== Epoch: 81, Valid Loss: 0.61, Valid Accuracy: 0.845\n",
      "0\n",
      "100\n",
      "200\n",
      "==== Epoch: 82, Train Loss: 0.03, Train Accuracy: 0.998\n",
      "==== Epoch: 82, Valid Loss: 0.62, Valid Accuracy: 0.854\n",
      "updated\n",
      "0\n",
      "100\n",
      "200\n",
      "==== Epoch: 83, Train Loss: 0.03, Train Accuracy: 0.997\n",
      "==== Epoch: 83, Valid Loss: 0.61, Valid Accuracy: 0.845\n",
      "0\n",
      "100\n",
      "200\n",
      "==== Epoch: 84, Train Loss: 0.03, Train Accuracy: 0.998\n",
      "==== Epoch: 84, Valid Loss: 0.59, Valid Accuracy: 0.857\n",
      "updated\n",
      "0\n",
      "100\n",
      "200\n",
      "==== Epoch: 85, Train Loss: 0.03, Train Accuracy: 0.998\n",
      "==== Epoch: 85, Valid Loss: 0.65, Valid Accuracy: 0.839\n",
      "updated\n",
      "0\n",
      "100\n",
      "200\n",
      "==== Epoch: 86, Train Loss: 0.03, Train Accuracy: 0.997\n",
      "==== Epoch: 86, Valid Loss: 0.60, Valid Accuracy: 0.853\n",
      "0\n",
      "100\n",
      "200\n",
      "==== Epoch: 87, Train Loss: 0.03, Train Accuracy: 0.997\n",
      "==== Epoch: 87, Valid Loss: 0.59, Valid Accuracy: 0.848\n",
      "0\n",
      "100\n",
      "200\n",
      "==== Epoch: 88, Train Loss: 0.02, Train Accuracy: 0.998\n",
      "==== Epoch: 88, Valid Loss: 0.60, Valid Accuracy: 0.842\n",
      "0\n",
      "100\n",
      "200\n",
      "==== Epoch: 89, Train Loss: 0.03, Train Accuracy: 0.998\n",
      "==== Epoch: 89, Valid Loss: 0.59, Valid Accuracy: 0.844\n",
      "0\n",
      "100\n",
      "200\n",
      "==== Epoch: 90, Train Loss: 0.03, Train Accuracy: 0.997\n",
      "==== Epoch: 90, Valid Loss: 0.61, Valid Accuracy: 0.852\n",
      "updated\n",
      "0\n",
      "100\n",
      "200\n",
      "==== Epoch: 91, Train Loss: 0.03, Train Accuracy: 0.998\n",
      "==== Epoch: 91, Valid Loss: 0.62, Valid Accuracy: 0.849\n",
      "0\n",
      "100\n",
      "200\n",
      "==== Epoch: 92, Train Loss: 0.03, Train Accuracy: 0.999\n",
      "==== Epoch: 92, Valid Loss: 0.62, Valid Accuracy: 0.852\n",
      "0\n",
      "100\n",
      "200\n",
      "==== Epoch: 93, Train Loss: 0.03, Train Accuracy: 0.998\n",
      "==== Epoch: 93, Valid Loss: 0.61, Valid Accuracy: 0.844\n",
      "0\n",
      "100\n",
      "200\n",
      "==== Epoch: 94, Train Loss: 0.04, Train Accuracy: 0.996\n",
      "==== Epoch: 94, Valid Loss: 0.59, Valid Accuracy: 0.849\n",
      "0\n",
      "100\n",
      "200\n",
      "==== Epoch: 95, Train Loss: 0.03, Train Accuracy: 0.998\n",
      "==== Epoch: 95, Valid Loss: 0.61, Valid Accuracy: 0.848\n",
      "updated\n",
      "0\n",
      "100\n",
      "200\n",
      "==== Epoch: 96, Train Loss: 0.03, Train Accuracy: 0.998\n",
      "==== Epoch: 96, Valid Loss: 0.59, Valid Accuracy: 0.856\n",
      "0\n",
      "100\n",
      "200\n",
      "==== Epoch: 97, Train Loss: 0.03, Train Accuracy: 0.997\n",
      "==== Epoch: 97, Valid Loss: 0.58, Valid Accuracy: 0.853\n",
      "0\n",
      "100\n",
      "200\n",
      "==== Epoch: 98, Train Loss: 0.02, Train Accuracy: 0.999\n",
      "==== Epoch: 98, Valid Loss: 0.59, Valid Accuracy: 0.849\n",
      "0\n",
      "100\n",
      "200\n",
      "==== Epoch: 99, Train Loss: 0.03, Train Accuracy: 0.997\n",
      "==== Epoch: 99, Valid Loss: 0.64, Valid Accuracy: 0.849\n",
      "0\n",
      "100\n",
      "200\n",
      "==== Epoch: 100, Train Loss: 0.02, Train Accuracy: 0.998\n",
      "==== Epoch: 100, Valid Loss: 0.58, Valid Accuracy: 0.857\n",
      "updated\n",
      "0\n",
      "100\n",
      "200\n",
      "==== Epoch: 101, Train Loss: 0.02, Train Accuracy: 0.998\n",
      "==== Epoch: 101, Valid Loss: 0.59, Valid Accuracy: 0.856\n",
      "0\n",
      "100\n",
      "200\n",
      "==== Epoch: 102, Train Loss: 0.02, Train Accuracy: 0.997\n",
      "==== Epoch: 102, Valid Loss: 0.58, Valid Accuracy: 0.857\n",
      "0\n",
      "100\n",
      "200\n",
      "==== Epoch: 103, Train Loss: 0.03, Train Accuracy: 0.998\n",
      "==== Epoch: 103, Valid Loss: 0.59, Valid Accuracy: 0.856\n",
      "0\n",
      "100\n",
      "200\n",
      "==== Epoch: 104, Train Loss: 0.02, Train Accuracy: 0.998\n",
      "==== Epoch: 104, Valid Loss: 0.59, Valid Accuracy: 0.852\n",
      "0\n",
      "100\n",
      "200\n",
      "==== Epoch: 105, Train Loss: 0.02, Train Accuracy: 0.999\n",
      "==== Epoch: 105, Valid Loss: 0.61, Valid Accuracy: 0.854\n",
      "updated\n",
      "0\n",
      "100\n",
      "200\n",
      "==== Epoch: 106, Train Loss: 0.02, Train Accuracy: 0.998\n",
      "==== Epoch: 106, Valid Loss: 0.59, Valid Accuracy: 0.852\n",
      "0\n",
      "100\n",
      "200\n",
      "==== Epoch: 107, Train Loss: 0.02, Train Accuracy: 0.999\n",
      "==== Epoch: 107, Valid Loss: 0.61, Valid Accuracy: 0.854\n",
      "0\n",
      "100\n",
      "200\n",
      "==== Epoch: 108, Train Loss: 0.02, Train Accuracy: 0.998\n",
      "==== Epoch: 108, Valid Loss: 0.59, Valid Accuracy: 0.849\n",
      "0\n",
      "100\n",
      "200\n",
      "==== Epoch: 109, Train Loss: 0.03, Train Accuracy: 0.997\n",
      "==== Epoch: 109, Valid Loss: 0.58, Valid Accuracy: 0.859\n",
      "updated\n",
      "0\n",
      "100\n",
      "200\n",
      "==== Epoch: 110, Train Loss: 0.02, Train Accuracy: 0.999\n",
      "==== Epoch: 110, Valid Loss: 0.59, Valid Accuracy: 0.857\n",
      "updated\n",
      "0\n",
      "100\n",
      "200\n",
      "==== Epoch: 111, Train Loss: 0.03, Train Accuracy: 0.999\n",
      "==== Epoch: 111, Valid Loss: 0.59, Valid Accuracy: 0.858\n",
      "0\n",
      "100\n",
      "200\n",
      "==== Epoch: 112, Train Loss: 0.03, Train Accuracy: 0.999\n",
      "==== Epoch: 112, Valid Loss: 0.62, Valid Accuracy: 0.850\n",
      "0\n",
      "100\n",
      "200\n",
      "==== Epoch: 113, Train Loss: 0.03, Train Accuracy: 0.999\n",
      "==== Epoch: 113, Valid Loss: 0.63, Valid Accuracy: 0.853\n",
      "0\n",
      "100\n",
      "200\n",
      "==== Epoch: 114, Train Loss: 0.03, Train Accuracy: 0.998\n",
      "==== Epoch: 114, Valid Loss: 0.59, Valid Accuracy: 0.857\n",
      "0\n",
      "100\n",
      "200\n",
      "==== Epoch: 115, Train Loss: 0.02, Train Accuracy: 0.999\n",
      "==== Epoch: 115, Valid Loss: 0.58, Valid Accuracy: 0.859\n",
      "updated\n",
      "0\n",
      "100\n",
      "200\n",
      "==== Epoch: 116, Train Loss: 0.02, Train Accuracy: 0.998\n",
      "==== Epoch: 116, Valid Loss: 0.59, Valid Accuracy: 0.856\n",
      "0\n",
      "100\n",
      "200\n",
      "==== Epoch: 117, Train Loss: 0.02, Train Accuracy: 0.998\n",
      "==== Epoch: 117, Valid Loss: 0.62, Valid Accuracy: 0.857\n",
      "0\n",
      "100\n",
      "200\n",
      "==== Epoch: 118, Train Loss: 0.02, Train Accuracy: 0.999\n",
      "==== Epoch: 118, Valid Loss: 0.59, Valid Accuracy: 0.850\n",
      "0\n",
      "100\n",
      "200\n",
      "==== Epoch: 119, Train Loss: 0.02, Train Accuracy: 1.000\n",
      "==== Epoch: 119, Valid Loss: 0.59, Valid Accuracy: 0.853\n",
      "0\n",
      "100\n",
      "200\n",
      "==== Epoch: 120, Train Loss: 0.02, Train Accuracy: 0.997\n",
      "==== Epoch: 120, Valid Loss: 0.61, Valid Accuracy: 0.861\n",
      "updated\n",
      "0\n",
      "100\n",
      "200\n",
      "==== Epoch: 121, Train Loss: 0.02, Train Accuracy: 0.999\n",
      "==== Epoch: 121, Valid Loss: 0.65, Valid Accuracy: 0.854\n",
      "0\n",
      "100\n",
      "200\n",
      "==== Epoch: 122, Train Loss: 0.02, Train Accuracy: 0.999\n",
      "==== Epoch: 122, Valid Loss: 0.59, Valid Accuracy: 0.853\n",
      "0\n",
      "100\n",
      "200\n",
      "==== Epoch: 123, Train Loss: 0.02, Train Accuracy: 0.998\n",
      "==== Epoch: 123, Valid Loss: 0.58, Valid Accuracy: 0.859\n",
      "0\n",
      "100\n",
      "200\n",
      "==== Epoch: 124, Train Loss: 0.02, Train Accuracy: 0.998\n",
      "==== Epoch: 124, Valid Loss: 0.59, Valid Accuracy: 0.861\n",
      "0\n",
      "100\n",
      "200\n",
      "==== Epoch: 125, Train Loss: 0.02, Train Accuracy: 0.999\n",
      "==== Epoch: 125, Valid Loss: 0.60, Valid Accuracy: 0.854\n",
      "updated\n",
      "0\n",
      "100\n",
      "200\n",
      "==== Epoch: 126, Train Loss: 0.03, Train Accuracy: 0.998\n",
      "==== Epoch: 126, Valid Loss: 0.58, Valid Accuracy: 0.854\n",
      "0\n",
      "100\n",
      "200\n",
      "==== Epoch: 127, Train Loss: 0.03, Train Accuracy: 0.998\n",
      "==== Epoch: 127, Valid Loss: 0.59, Valid Accuracy: 0.861\n",
      "0\n",
      "100\n",
      "200\n",
      "==== Epoch: 128, Train Loss: 0.02, Train Accuracy: 0.998\n",
      "==== Epoch: 128, Valid Loss: 0.60, Valid Accuracy: 0.852\n",
      "0\n",
      "100\n",
      "200\n",
      "==== Epoch: 129, Train Loss: 0.02, Train Accuracy: 0.999\n",
      "==== Epoch: 129, Valid Loss: 0.58, Valid Accuracy: 0.857\n",
      "0\n",
      "100\n",
      "200\n",
      "==== Epoch: 130, Train Loss: 0.02, Train Accuracy: 0.999\n",
      "==== Epoch: 130, Valid Loss: 0.59, Valid Accuracy: 0.856\n",
      "updated\n",
      "0\n",
      "100\n",
      "200\n",
      "==== Epoch: 131, Train Loss: 0.02, Train Accuracy: 0.999\n",
      "==== Epoch: 131, Valid Loss: 0.59, Valid Accuracy: 0.850\n",
      "0\n",
      "100\n",
      "200\n",
      "==== Epoch: 132, Train Loss: 0.02, Train Accuracy: 0.998\n",
      "==== Epoch: 132, Valid Loss: 0.60, Valid Accuracy: 0.854\n",
      "0\n",
      "100\n",
      "200\n",
      "==== Epoch: 133, Train Loss: 0.02, Train Accuracy: 0.999\n",
      "==== Epoch: 133, Valid Loss: 0.60, Valid Accuracy: 0.853\n",
      "0\n",
      "100\n",
      "200\n",
      "==== Epoch: 134, Train Loss: 0.02, Train Accuracy: 0.998\n",
      "==== Epoch: 134, Valid Loss: 0.59, Valid Accuracy: 0.842\n",
      "0\n",
      "100\n",
      "200\n",
      "==== Epoch: 135, Train Loss: 0.02, Train Accuracy: 0.999\n",
      "==== Epoch: 135, Valid Loss: 0.60, Valid Accuracy: 0.854\n",
      "updated\n",
      "0\n",
      "100\n",
      "200\n",
      "==== Epoch: 136, Train Loss: 0.02, Train Accuracy: 0.999\n",
      "==== Epoch: 136, Valid Loss: 0.60, Valid Accuracy: 0.854\n",
      "0\n",
      "100\n",
      "200\n",
      "==== Epoch: 137, Train Loss: 0.02, Train Accuracy: 0.999\n",
      "==== Epoch: 137, Valid Loss: 0.61, Valid Accuracy: 0.845\n",
      "0\n",
      "100\n",
      "200\n",
      "==== Epoch: 138, Train Loss: 0.02, Train Accuracy: 0.999\n",
      "==== Epoch: 138, Valid Loss: 0.59, Valid Accuracy: 0.857\n",
      "0\n",
      "100\n",
      "200\n",
      "==== Epoch: 139, Train Loss: 0.02, Train Accuracy: 0.998\n",
      "==== Epoch: 139, Valid Loss: 0.60, Valid Accuracy: 0.852\n",
      "0\n",
      "100\n",
      "200\n",
      "==== Epoch: 140, Train Loss: 0.02, Train Accuracy: 0.999\n",
      "==== Epoch: 140, Valid Loss: 0.60, Valid Accuracy: 0.849\n",
      "updated\n",
      "0\n",
      "100\n",
      "200\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-d00f850146c8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m             \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msignal_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m             \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gisan_project1/yongwoo/signal_process.py\u001b[0m in \u001b[0;36msignal_process\u001b[0;34m(audio_samples, sr, method)\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'logmelspectrogram'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mmel_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorchaudio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMelSpectrogram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m22050\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_fft\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2048\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhop_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1024\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalized\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0mmel_spec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmel_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m         \u001b[0mlog_mel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclamp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmel_spec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlog_mel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/[/anaconda3]/envs/gisan/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/[/anaconda3]/envs/gisan/lib/python3.7/site-packages/torchaudio/transforms.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, waveform)\u001b[0m\n\u001b[1;32m    424\u001b[0m             \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mMel\u001b[0m \u001b[0mfrequency\u001b[0m \u001b[0mspectrogram\u001b[0m \u001b[0mof\u001b[0m \u001b[0msize\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mn_mels\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m         \"\"\"\n\u001b[0;32m--> 426\u001b[0;31m         \u001b[0mspecgram\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspectrogram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwaveform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    427\u001b[0m         \u001b[0mmel_specgram\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmel_scale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspecgram\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmel_specgram\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/[/anaconda3]/envs/gisan/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/[/anaconda3]/envs/gisan/lib/python3.7/site-packages/torchaudio/transforms.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, waveform)\u001b[0m\n\u001b[1;32m     82\u001b[0m         \"\"\"\n\u001b[1;32m     83\u001b[0m         return F.spectrogram(waveform, self.pad, self.window, self.n_fft, self.hop_length,\n\u001b[0;32m---> 84\u001b[0;31m                              self.win_length, self.power, self.normalized)\n\u001b[0m\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/[/anaconda3]/envs/gisan/lib/python3.7/site-packages/torchaudio/functional.py\u001b[0m in \u001b[0;36mspectrogram\u001b[0;34m(waveform, pad, window, n_fft, hop_length, win_length, power, normalized)\u001b[0m\n\u001b[1;32m    160\u001b[0m     \u001b[0;31m# default values are consistent with librosa.core.spectrum._spectrogram\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m     spec_f = torch.stft(\n\u001b[0;32m--> 162\u001b[0;31m         \u001b[0mwaveform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_fft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhop_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwin_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwindow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"reflect\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m     )\n\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/[/anaconda3]/envs/gisan/lib/python3.7/site-packages/torch/functional.py\u001b[0m in \u001b[0;36mstft\u001b[0;34m(input, n_fft, hop_length, win_length, window, center, pad_mode, normalized, onesided)\u001b[0m\n\u001b[1;32m    461\u001b[0m         \u001b[0mextended_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0msignal_dim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m         \u001b[0mpad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_fft\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 463\u001b[0;31m         \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextended_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad_mode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    464\u001b[0m         \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0msignal_dim\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_VF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstft\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_fft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhop_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwin_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwindow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalized\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0monesided\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/[/anaconda3]/envs/gisan/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36m_pad\u001b[0;34m(input, pad, mode, value)\u001b[0m\n\u001b[1;32m   3556\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'3D tensors expect 2 values for padding'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3557\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'reflect'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3558\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreflection_pad1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3559\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'replicate'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3560\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplication_pad1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "is_test_mode = False\n",
    "\n",
    "if not is_test_mode:\n",
    "    \n",
    "    # Load Dataset and Dataloader\n",
    "    train_dataset = KeyDataset(metadata_path=metadata_path, audio_dir=audio_dir, sr=sr, split='training')\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    valid_dataset = KeyDataset(metadata_path=metadata_path, audio_dir=audio_dir, sr=sr, split='validation')\n",
    "    valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=True)\n",
    "    model = ResNet()\n",
    "#     model = DenseNet()\n",
    "    model = model.to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=1e-3,momentum=0.9, weight_decay=1e-4)\n",
    "    best_accuracy = 0\n",
    "\n",
    "    # Training and Validation\n",
    "    for epoch in range(n_epochs):\n",
    "        \n",
    "        model.train()\n",
    "\n",
    "        train_correct = 0\n",
    "        train_loss = 0\n",
    "        i=0\n",
    "        j=0\n",
    "        for idx, (features, labels) in enumerate(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "            features = signal_process(features, sr=sr, method=method).to(device)\n",
    "            features = features.unsqueeze(1)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            output = model(features)\n",
    "            loss = criterion(output, labels)\n",
    "#             features = features.squeeze(1)\n",
    "            train_loss += loss.item()\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            preds = output.argmax(dim=-1, keepdim=True)\n",
    "            train_correct += (preds.squeeze() == labels).float().sum()\n",
    "            if i%100 ==0:\n",
    "                print(i)\n",
    "            i+=1\n",
    "        print(\"==== Epoch: %d, Train Loss: %.2f, Train Accuracy: %.3f\" % (\n",
    "            epoch, train_loss / len(train_loader), train_correct / len(train_dataset)))\n",
    "\n",
    "        model.eval()\n",
    "\n",
    "        valid_correct = 0\n",
    "        valid_loss = 0\n",
    "\n",
    "        for idx, (features, labels) in enumerate(valid_loader):\n",
    "            features = signal_process(features, sr=sr, method=method).to(device)\n",
    "            features = features.unsqueeze(1)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            output = model(features)\n",
    "            loss = criterion(output, labels)\n",
    "#             features = features.squeeze(1)\n",
    "            valid_loss += loss.item()\n",
    "\n",
    "            preds = output.argmax(dim=-1, keepdim=True)\n",
    "            valid_correct += (preds.squeeze() == labels).float().sum()\n",
    "            \n",
    "        print(\"==== Epoch: %d, Valid Loss: %.2f, Valid Accuracy: %.3f\" % (\n",
    "            epoch, valid_loss / len(valid_loader), valid_correct / len(valid_dataset)))\n",
    "        valid_accuracy = valid_correct/len(valid_dataset)\n",
    "        if valid_accuracy>0.73:\n",
    "            for param_group in optimizer.param_groups:\n",
    "                param_group['lr'] = 1e-4\n",
    "        elif valid_accuracy>0.83:\n",
    "            for param_group in optimizer.param_groups:\n",
    "                param_group['lr'] = 1e-5\n",
    "                \n",
    "        if valid_accuracy> best_accuracy:\n",
    "            best_accuracy = valid_accuracy\n",
    "            torch.save(model.state_dict(), best_saved_model) # official recommended\n",
    "            print('updated')\n",
    "        elif epoch%5==0:\n",
    "            torch.save(model.state_dict(), best_saved_model) # official recommended\n",
    "            print('updated')\n",
    "            \n",
    "\n",
    "# elif is_test_mode:\n",
    "\n",
    "#     # Load Dataset and Dataloader\n",
    "#     test_dataset = KeyDataset(metadata_path=metadata_path, audio_dir=audio_dir, sr=sr, split='test')\n",
    "#     test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "#     # Restore model\n",
    "#     model = torch.load(restore_path).to(device)\n",
    "#     print('==== Model restored : %s' % restore_path)\n",
    "\n",
    "#     # TODO: IMPORTANT!! MUST CALCULATE ACCURACY ! You may change this part, but must print accuracy in the right manner\n",
    "\n",
    "#     test_correct = 0\n",
    "\n",
    "#     for features, labels in test_loader:\n",
    "#         features = signal_process(features, sr=sr, method=method).to(device)\n",
    "#         labels = labels.to(device)\n",
    "\n",
    "#         output = model(features)\n",
    "\n",
    "#         preds = output.argmax(dim=-1, keepdim=True)\n",
    "#         test_correct += (preds.squeeze() == labels).float().sum()\n",
    "\n",
    "#     print(\"=== Test accuracy: %.3f\" % (test_correct / len(test_dataset)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
